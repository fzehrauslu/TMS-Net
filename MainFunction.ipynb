{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function,division\n",
    "import sys\n",
    "sys.path.append('/home/oem/vision')\n",
    "sys.path.append('/home/oem/miniconda3/lib/python3.9/site-packages/skimage')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from os.path import  join\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.optim.lr_scheduler import ExponentialLR as ExponentialLR\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import medpy\n",
    "import PIL\n",
    "import json\n",
    "\n",
    "from TMSNet_Train_Test import train, test,testWithAdversarialNoise\n",
    "from TMSNet import TMSNet\n",
    "import pdb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from DataLoader import get_data\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device=torch.device(\"cuda:0\")  \n",
    "\n",
    "class option:\n",
    "    def __init__(self,PathToTrainingFolder,PathToSaveTrainedModels,Dataset,AttackType,AttackNumber):\n",
    "        \n",
    "        self.PathToTrainingFolder = PathToTrainingFolder\n",
    "        self.Dataset=Dataset       \n",
    "        if self.Dataset=='Atrium2018':\n",
    "            self.InputSize = 128           \n",
    "            self.weight_decay=0.001 \n",
    "            self.batchSize=8\n",
    "        elif self.Dataset=='Atrium2013':\n",
    "            self.InputSize = 192\n",
    "            self.weight_decay=0.01 \n",
    "            self.batchSize=4\n",
    "            \n",
    "        self.lr =0.0005\n",
    "        self.AttackNumber= AttackNumber #3\n",
    "        self.AttackType=AttackType #'FGSM'\n",
    "        self.cuda = True\n",
    "        self.nEpochs = 20\n",
    "        self.gammaForScheduler=0.95 \n",
    "        self.FolderName='8'\n",
    "        self.threads=0\n",
    "        self.testBatchSize=1\n",
    "        self.PathToSaveTrainedModels=PathToSaveTrainedModels\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "class TrainingParameters:\n",
    "    def __init__(self,device,training_data_loader_All,training_data_loader_A,training_data_loader_C,training_data_loader_S,val_data_loader_All,val_data_loader_A,val_data_loader_C,val_data_loader_S,testing_data_loader_S):\n",
    "        \n",
    "        self.initial_seed=23789 \n",
    "        #self.optimizer=optimizer\n",
    "        self.training_data_loader_All=training_data_loader_All\n",
    "        self.training_data_loader_A=training_data_loader_A\n",
    "        self.training_data_loader_C=training_data_loader_C\n",
    "        self.training_data_loader_S=training_data_loader_S\n",
    "             \n",
    "        self.val_data_loader_All=val_data_loader_All           \n",
    "        self.val_data_loader_A=val_data_loader_A\n",
    "        self.val_data_loader_C=val_data_loader_C\n",
    "        self.val_data_loader_S=val_data_loader_S\n",
    "        self.testing_data_loader_S=testing_data_loader_S\n",
    "        self.device=device\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(epoch):\n",
    "    model_out_path = join(opt.PathToSaveTrainedModels,\"epoch_{}.pth\".format(epoch))\n",
    "    torch.save(model.state_dict(), model_out_path)\n",
    "    \n",
    "    \n",
    "    fig, [ax1,ax2] = plt.subplots( nrows=1, ncols=2 )  # create figure & 1 axis\n",
    "    ax1.plot(trainingLoss)\n",
    "    ax1.set(xlabel='epochs', ylabel='TrainingLoss')  \n",
    "    ax2.plot(validationLoss)\n",
    "    ax2.set(xlabel='epochs', ylabel='ValidationLoss')  \n",
    "\n",
    "    plt.savefig(join(opt.PathToSaveTrainedModels,\"ErrorPlot_{}_Epoch.png\".format(epoch)))\n",
    "    plt.show()\n",
    "    plt.close(fig)     \n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "\n",
    "    model=TMSNet(W=10).to(device)\n",
    "    \n",
    "    ##Â update paths accordingly for your computer\n",
    "    PathToSaveTrainedModels=join(\"/TrainedModels\",str('2013'))\n",
    "    PathToTrainingFolder = \"/Training\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    Dataset='Atrium2013'         \n",
    "    AttackType='FGSM' # or IterativeFGSM or Rician\n",
    "    AttackNumber=0 #1 or 3\n",
    "    \n",
    "    \n",
    "    opt=option(PathToTrainingFolder,PathToSaveTrainedModels,Dataset,AttackType,AttackNumber)\n",
    "    optimizer  =optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=opt.lr) \n",
    "    scheduler=ExponentialLR(optimizer,gamma=opt.gammaForScheduler) \n",
    "    \n",
    "    \n",
    "    MainPath=\"/Datasets/Atrium2013/\"\n",
    "    dataPath=os.path.join(MainPath,'All')\n",
    "    train_set=get_data(opt,dataPath,DataloaderType='training')\n",
    "    training_data_loader_All = DataLoader(dataset=train_set, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=True,drop_last=False)\n",
    "\n",
    "    val_set = get_data(opt,dataPath,DataloaderType='validation')\n",
    "    val_data_loader_All = DataLoader(dataset=val_set, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    dataPath=os.path.join(MainPath,'A')\n",
    "    train_set = get_data(opt,dataPath,DataloaderType='training')\n",
    "    training_data_loader_A = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True,pin_memory=False,drop_last=False)\n",
    "\n",
    "    val_set = get_data(opt,dataPath,DataloaderType='validation')\n",
    "    val_data_loader_A = DataLoader(dataset=val_set, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=False)\n",
    "\n",
    "\n",
    "    ##########\n",
    "\n",
    "    dataPath=os.path.join(MainPath,'C')\n",
    "    train_set_C = get_data(opt,dataPath,DataloaderType='training')\n",
    "    training_data_loader_C = DataLoader(dataset=train_set_C, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=False,drop_last=False)\n",
    "\n",
    "\n",
    "    val_set = get_data(opt,dataPath,DataloaderType='validation')\n",
    "    val_data_loader_C = DataLoader(dataset=val_set, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "    dataPath=os.path.join(MainPath,'S')\n",
    "    train_set_S = get_data(opt,dataPath,DataloaderType='training')\n",
    "    training_data_loader_S = DataLoader(dataset=train_set_S, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=False,drop_last=False)\n",
    "\n",
    "    val_set = get_data(opt,dataPath,DataloaderType='validation')\n",
    "    val_data_loader_S = DataLoader(dataset=val_set, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=False)\n",
    "\n",
    "    test_set_S =get_data(opt,dataPath,DataloaderType='test') \n",
    "    testing_data_loader_S = DataLoader(dataset=test_set_S, num_workers=0, batch_size=opt.testBatchSize, shuffle=False,pin_memory=False)\n",
    "\n",
    "   \n",
    "    TranPara=TrainingParameters(device,training_data_loader_All,training_data_loader_A,training_data_loader_C, training_data_loader_S,val_data_loader_All, \n",
    "                                val_data_loader_A,val_data_loader_C,val_data_loader_S,testing_data_loader_S)\n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    it=0\n",
    "\n",
    "    dice=[]\n",
    "    hfDistance=[]\n",
    "    ASSD=[]\n",
    "    Jaccard=[]\n",
    "\n",
    "    \n",
    "\n",
    "    trainingLoss=[]\n",
    "    validationLoss=[]\n",
    "\n",
    "    epsilon=0\n",
    "\n",
    "    for epoch in range(opt.nEpochs):\n",
    "\n",
    "\n",
    "        # for test with adversarial noise, please uncomment the part below\n",
    "        ''' \n",
    "        if opt.AttackType=='Rician':\n",
    "            noiseRange=[10,15,20,25]\n",
    "        else:\n",
    "            noiseRange=[0.01,0.02,0.03,0.04]\n",
    "\n",
    "        for epsilon in noiseRange:\n",
    "\n",
    "            dice=[]\n",
    "            hfDistance=[]\n",
    "            surface_distance=[]\n",
    "            JaccardSimilarity=[]\n",
    "            CosineSimilarities=[]\n",
    "            \n",
    "            dice,hfDistance,ASSD,Jaccard,CosineSimilarities=testWithAdversarialNoise(TranPara,opt,model,device,dice,hfDistance,ASSD,Jaccard,CosineSimilarities,epsilon)\n",
    "            data={\"dice\":dice, \"hfDistance\":hfDistance,\"ASSD\":ASSD,\"Jaccard\":Jaccard,'CosineSimilarities'}\n",
    "            #testWithAdversarialNoise\n",
    "            print (\"        \")\n",
    "            print (\" epsilon  \",epsilon)\n",
    "\n",
    "            print (\"        \")\n",
    "            print(np.mean(ASSD),np.mean(hfDistance),np.mean(dice),np.mean(Jaccard),np.mean(CosineSimilarities))\n",
    "            print(np.std(ASSD),np.std(hfDistance),np.std(dice),np.std(Jaccard),np.std(CosineSimilarities))\n",
    "            with open(join(opt.PathToSaveTrainedModels,'PerformanceMetrics_'+opt.AttackType+'_'+str(opt.AttackNumber)+'_'+str(epsilon)+'.json'), 'w') as fp:\n",
    "                json.dump(data, fp)\n",
    "\n",
    "\n",
    "        pdb.set_trace()\n",
    "        '''\n",
    "\n",
    "       \n",
    "        \n",
    "        print(count_parameters(model))\n",
    "        \n",
    "        model,optimizer, trainLoss, valLoss= train(TranPara,opt,model,epoch,optimizer)\n",
    "        trainingLoss.append(trainLoss)\n",
    "        validationLoss.append(valLoss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        it=it+1\n",
    "        print(\"TrainingEpoch:\"+str(it))\n",
    "        if epoch%1 == 0:\n",
    "            checkpoint(epoch)\n",
    "        if epoch%1 == 0 and epoch>9:\n",
    "\n",
    "            dice=[]\n",
    "            hfDistance=[]\n",
    "            surface_distance=[]\n",
    "            JaccardSimilarity=[]\n",
    "            CosineSimilarities=[]\n",
    "\n",
    "            dice,hfDistance,ASSD,Jaccard,CosineSimilarities=test(TranPara,opt,model,device,dice,hfDistance,ASSD,Jaccard,CosineSimilarities)\n",
    "\n",
    "            data={\"dice\":dice, \"hfDistance\":hfDistance,\"ASSD\":ASSD,\"Jaccard\":Jaccard}\n",
    "            print(np.mean(ASSD),np.mean(hfDistance),np.mean(dice),np.mean(Jaccard))\n",
    "            print(np.std(ASSD),np.std(hfDistance),np.std(dice),np.std(Jaccard))\n",
    "            with open(join(opt.PathToSaveTrainedModels,'PerformanceMetrics.json'), 'w') as fp:\n",
    "                json.dump(data, fp)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CosineSimilarities,Jaccard,'*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CosineSimilarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
